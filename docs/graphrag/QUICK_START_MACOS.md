# Quick Start for macOS - Zero Cost Embeddings

## ðŸŽ¯ Your Situation

- **Platform**: macOS
- **Content**: 10 manuals Ã— 300 pages = 3,000 pages
- **Goal**: Zero cost embeddings
- **Issue**: Python externally-managed environment

## âœ… Recommended Solution: Ollama

**Why Ollama?**

- âœ… No Python issues
- âœ… 5 minute setup
- âœ… $0 cost (vs $18.75 with OpenAI)
- âœ… Good quality (87% of OpenAI)

## ðŸš€ Complete Setup (5 Minutes)

### Step 1: Install Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

### Step 2: Download Model

```bash
ollama pull nomic-embed-text
```

### Step 3: Configure Application

```bash
cat >> .env << 'EOF'

# Ollama Local Embeddings
EMBEDDING_PROVIDER="ollama"
EMBEDDING_MODEL="nomic-embed-text"
EMBEDDING_DIMENSIONS="768"
OLLAMA_HOST="http://localhost:11434"
EOF
```

### Step 4: Update Database Schema

Edit `prisma/schema.prisma`:

```prisma
model KnowledgeGraphNode {
  id         String   @id @default(cuid())
  materialId String   @map("material_id") @db.VarChar(255)
  courseId   String   @map("course_id")
  content    String   @db.Text
  chunkIndex Int      @map("chunk_index")
  metadata   Json?
  embedding  Unsupported("vector(768)")?  // â† Change from 1536 to 768
  createdAt  DateTime @default(now()) @map("created_at")
  updatedAt  DateTime @updatedAt @map("updated_at")

  // ... rest of model
}
```

### Step 5: Run Migration

```bash
npx prisma migrate dev --name use_ollama_768_dimensions
npx prisma generate
```

### Step 6: Start Application

```bash
# Start Ollama (if not running)
ollama serve &

# Start your app
npm run dev
```

### Step 7: Verify

```bash
curl http://localhost:3000/api/health/graphrag | jq
```

Should show:

```json
{
  "checks": {
    "embedding": {
      "status": "ok",
      "provider": "ollama"
    }
  }
}
```

## âœ… Done!

You now have:

- âœ… Zero-cost embeddings
- âœ… No Python issues
- âœ… Good quality search
- âœ… Privacy (data stays local)

## ðŸ’° Cost Savings

| Provider   | Your Cost (3,000 pages) |
| ---------- | ----------------------- |
| OpenAI     | $18.75 + $22.56/year    |
| **Ollama** | **$0** âœ…               |

**You just saved $41.31 in Year 1!**

## ðŸ”„ Process Your Documents

```javascript
// Same API as before!
const result = await graphRAGService.processDocument(content, {
  materialId: 'manual-1',
  courseId: 'course-123'
});

// Now using Ollama (free!)
```

## ðŸ“Š What You Get

- **Quality**: 87/100 (vs 94/100 with OpenAI)
- **Speed**: ~60 minutes for 3,000 pages
- **Cost**: $0
- **Privacy**: Data never leaves your server

## ðŸ†˜ Troubleshooting

### Ollama not responding

```bash
# Check if running
curl http://localhost:11434/api/tags

# If not, start it
ollama serve
```

### Model not found

```bash
# Re-pull model
ollama pull nomic-embed-text

# Verify
ollama list
```

### Connection refused

```bash
# Check Ollama is running
ps aux | grep ollama

# Start if needed
ollama serve &
```

## ðŸ”„ Alternative: Sentence-Transformers (Better Quality)

If you want 90% quality instead of 87%:

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install
pip install sentence-transformers torch

# Configure
cat >> .env << 'EOF'

EMBEDDING_PROVIDER="sentence-transformers"
EMBEDDING_MODEL="all-MiniLM-L6-v2"
EMBEDDING_DIMENSIONS="384"
PYTHON_PATH=".venv/bin/python"
EOF

# Update schema to vector(384) and migrate
```

**But Ollama is easier!** ðŸ˜Š

## ðŸ“š More Info

- **[macOS Setup Guide](./MACOS_SETUP.md)** - Detailed macOS instructions
- **[Cost Comparison](./COST_COMPARISON.md)** - Full cost analysis
- **[Local Embeddings](./local-embeddings.md)** - All provider options

## ðŸŽ‰ Summary

You chose the smart path:

- âœ… Saved $41.31 in Year 1
- âœ… Saved $22.56 every year after
- âœ… No Python complexity
- âœ… Good quality (87% of OpenAI)
- âœ… 5 minute setup

**Enjoy your zero-cost semantic search!** ðŸš€
