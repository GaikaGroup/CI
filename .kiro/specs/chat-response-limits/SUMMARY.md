# Краткая сводка: Размеры ответов и контекста

## Текущее состояние

### Размер ответа бота

**OpenAI:**

- Обычный: **500 токенов** (~375 слов, ~2000 символов)
- Детальный: **4000 токенов** (~3000 слов, ~16000 символов)

**Ollama:**

- Обычный: **512 токенов** (~384 слова, ~2048 символов)
- Контекстное окно: **2048 токенов** (вся история разговора)

### Размер сессии

- ❌ **Нет лимита** на количество сообщений в истории
- Все сообщения передаются в API без ограничений
- При длинной сессии (10+ вопросов) может превысить контекстное окно модели

## Проблемы

1. **Маленький размер ответа** - 500 токенов недостаточно для подробных объяснений
2. **Неограниченная история** - может превысить контекстное окно
3. **Маленькое контекстное окно Ollama** - 2048 токенов хватает только на 3-4 вопроса

## Рекомендации

### 1. Увеличить размер ответа

```env
# OpenAI
VITE_OPENAI_MAX_TOKENS=1500  # было 500
VITE_OPENAI_DETAILED_MAX_TOKENS=6000  # было 4000

# Ollama
VITE_OLLAMA_MAX_TOKENS=1024  # было 512
VITE_OLLAMA_NUM_CTX=4096  # было 2048
```

**Результат:**

- Обычный ответ: ~1125 слов (~6000 символов) ✅
- Детальный ответ: ~4500 слов (~24000 символов) ✅

### 2. Ограничить историю сообщений

Добавить в `src/routes/api/chat/+server.js`:

```javascript
// Берем только последние 20 сообщений (10 пар вопрос-ответ)
const MAX_HISTORY_MESSAGES = 20;

if (sessionContext?.history && sessionContext.history.length > 0) {
  const recentHistory = sessionContext.history.slice(-MAX_HISTORY_MESSAGES);
  recentHistory.forEach((entry) => {
    messages.push({ role: entry.role, content: entry.content });
  });
}
```

### 3. Оптимизировать системные промпты

Текущие промпты очень длинные (~2000 символов).
Можно сократить до ~800 символов, убрав повторения.

## Следующие шаги

1. Обновить `.env` файл с новыми лимитами
2. Добавить ограничение истории в API endpoint
3. Оптимизировать системные промпты
4. Протестировать на длинных сессиях
